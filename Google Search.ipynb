{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43ac4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "from pywikihow import WikiHow, search_wikihow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c327ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_summary(keyword):\n",
    "    try:\n",
    "        result=wikipedia.summary(keyword, sentences=2)\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        #Option 1: Wikipedia Suggest\n",
    "        suggest = wikipedia.suggest(keyword)\n",
    "        result = wikipedia.summary(suggest)\n",
    "        #Option 2: User give an input\n",
    "\n",
    "#         print(\"Your Choice of topic is disambiguous, Choose the topic below:\")\n",
    "#         for i in range(len(e.options)):\n",
    "#             print(i+1,\". \" ,e.options[i])\n",
    "#         user_option=int(input(\"Type the topic number [example: 1] : \"))\n",
    "#         result=wikipedia.summary(e.options[user_option-1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a40fd220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import wikipedia\n",
    "\n",
    "headers = {\n",
    "    'User-agent':\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.67 Safari/537.36'\n",
    "}\n",
    "\n",
    "def wiki_summary_google(keyword):\n",
    "    try:\n",
    "        #Wikipedia\n",
    "        result1=wikipedia.summary(keyword, sentences=2)\n",
    "        \n",
    "    except:\n",
    "        #Google - Oxford Dictionary\n",
    "        html = requests.get(f'https://www.google.com/search?q=what+is+the+definition+of+\"{keyword}', headers=headers)\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "        try:\n",
    "            result1=soup.select_one('.LTKOO .sY7ric').text \n",
    "        except:\n",
    "            result1=\"\"\n",
    "    return result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3370691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the use and development of computer systems that are able to learn and adapt without following explicit instructions, by using algorithms and statistical models to analyze and draw inferences from patterns in data.\"the application of machine learning to biological databases has increased\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_summary_google(\"machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c97924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_to(question):\n",
    "    max_results = 1  # default for optional argument is 10\n",
    "    how_tos = search_wikihow(question, max_results)\n",
    "    assert len(how_tos) == 1\n",
    "    #how_tos[0].print()\n",
    "    res=how_tos[0].summary\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4501c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clean_text(text): \n",
    "    stop_words = set( stopwords.words('english') + list(punctuation) +[\"''\", \"»\", \"‘\", \"‘\", \"’\", '“', '”', '•', '■', '♦️'])\n",
    "    tag_map = defaultdict(lambda : wn.NOUN)\n",
    "    tag_map['J'] = wn.ADJ\n",
    "    tag_map['V'] = wn.VERB\n",
    "    tag_map['R'] = wn.ADV\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemma_function = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for token, tag in pos_tag(tokens):\n",
    "        item = lemma_function.lemmatize(token, tag_map[tag[0]])\n",
    "        if item not in stop_words:\n",
    "            lemmas.append(item)\n",
    "    #lemmas= ' '.join(lemmas)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "821b43f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'User-agent':\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.67 Safari/537.36'\n",
    "}\n",
    "\n",
    "def ask_google(question):\n",
    "\n",
    "    html = requests.get(f'https://www.google.com/search?q=\"{question}', headers=headers)\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    \n",
    "\n",
    "    answer1=''\n",
    "    answer2=''\n",
    "    q=question.lower()\n",
    "    print('Question:', q)\n",
    "    if \"who\" in q:\n",
    "        answer1 = soup.select_one('.FLP8od').text #\"LEsW6e DVGBBd\"><div class=\"wDYxhc NFQFxe oHglmf xzPb7d\" \n",
    "        answer2 = soup.select_one('.NFQFxe').text\n",
    "        #print('Who is ___, exp: Who is the president of United States?')\n",
    "        if answer2 !=\"\":\n",
    "            return f\"{answer1} - {answer2}\"\n",
    "        return answer1\n",
    "    elif \"where\" in q:\n",
    "        answer1=soup.select_one('.hgKElc').text \n",
    "        #print('Q: where is? ')\n",
    "        return answer1\n",
    "    elif \"when\" in q:\n",
    "        answer1=soup.select_one('.zCubwf').text \n",
    "        #print('Q: when is? ')\n",
    "        return answer1\n",
    "    elif \"how\" in q:\n",
    "        print('how')\n",
    "        if \"how to\" in q:\n",
    "            answer1=how_to(q)\n",
    "            #print('how to____ source: wikihow? ')\n",
    "            return answer1\n",
    "        else:\n",
    "            try:\n",
    "                answer1=soup.select_one('.ILfuVd').text \n",
    "                #print('Q: why is ___ cond? ')\n",
    "                return answer1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            \n",
    "\n",
    "    try:\n",
    "        answer1=soup.select_one('.ILfuVd').text \n",
    "        #print('Q: why is ___ cond? ')\n",
    "        return answer1 \n",
    "    except:\n",
    "        try:\n",
    "            answer1 = soup.select_one('.IZ6rdc').text\n",
    "            answer2 = soup.select_one('.NFQFxe').text.strip(answer1)\n",
    "            #print('Q: ___ belongs to which ____?, exp:Google belongs to which country?')\n",
    "            if answer2 !=\"\":\n",
    "                return f\"{answer1} - {answer2}\"\n",
    "            return answer1\n",
    "        except:\n",
    "            try:\n",
    "                answer1 = soup.select_one('.RqBzHd').text \n",
    "                #print('Q: What is the most ____ NOUN? - list')\n",
    "                return answer1\n",
    "            except:\n",
    "                try:\n",
    "                    answer1=soup.select_one('.d9FyLd').text \n",
    "                    print('cond4')\n",
    "                    return answer1\n",
    "                except:\n",
    "                    try:\n",
    "                        answer1=soup.select_one('.hgKElc').text \n",
    "                        print('TRY - Q: where is? what is the most __ ?')\n",
    "                        return answer1\n",
    "                    except:\n",
    "                        try:\n",
    "                            answer1 = soup.select_one('.FLP8od').text #\"LEsW6e DVGBBd\"><div class=\"wDYxhc NFQFxe oHglmf xzPb7d\" \n",
    "                            answer2 = soup.select_one('.NFQFxe').text\n",
    "                            print('TRY - Who is ___, exp: Who is the president of United States?')\n",
    "                            if answer2 !=\"\":\n",
    "                                return f\"{answer1} - {answer2}\"\n",
    "                            return answer1\n",
    "                        except:\n",
    "                            try:\n",
    "                                #is __ better than ___?\n",
    "                                answer1=soup.select_one('.iKJnec').text \n",
    "                                print('cond is __ better than ___? ')\n",
    "                                return answer1\n",
    "                            except:\n",
    "                                try:\n",
    "                                    answer1=soup.select_one('.zCubwf').text \n",
    "                                    print('TRY - Q: when is? ')\n",
    "                                    return answer1\n",
    "                                except:\n",
    "                                        # answer1=soup.select_one('.LTKOO').text \n",
    "                                        # print('TRY - Q: what is definition of? ')\n",
    "                                        # return answer1\n",
    "\n",
    "                                        if q.split()[0]=='what' or \"meaning\" in q or \"definition\" in q:\n",
    "                                            #print(\"TRY - ask wiki now, so it might be shitty\")\n",
    "                                            #if \"what is\" in question.lower():\n",
    "                                            #answer1 = wiki_summary(question.strip('?').upper().strip('WHAT IS'))\n",
    "                                            key = ' '.join(clean_text(question))\n",
    "                                            #print('key',key)\n",
    "                                            #search_list=[x.lower() for x in wikipedia.search(key)]\n",
    "                                            #if key.lower() in search_list:\n",
    "                                            answer1 = wiki_summary_google(key)\n",
    "                                            #print(answer1)\n",
    "                                            if answer1 != \"\":\n",
    "                                                return answer1\n",
    "                                            answer1 = f\"I am sorry I don't know about the answer to the question - {question}. I will keep learning\"\n",
    "\n",
    "                                        else:\n",
    "                                            answer1= f\"I am sorry I don't know about the answer to the question - {question}. I will keep learning\"\n",
    "\n",
    "    answer2=answer2.split('.')[0]\n",
    "    return answer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17b2d476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key='book'\n",
    "search_list=[x.lower() for x in wikipedia.search(key)]\n",
    "key.lower() in search_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32894d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is the fastest bike\n",
      "Q: why is ___ cond? \n",
      "What is the #1 fastest bike in the world? The turbine-powered MTT 420-RR is currently the fastest bike in the world with a top speed of 273 mph (439 km/h).\n"
     ]
    }
   ],
   "source": [
    "print(ask_google('what is the fastest bike'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64bc90d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is the definition of machine learning\n",
      "TRY - Q: what is definition of? \n",
      "the use and development of computer systems that are able to learn and adapt without following explicit instructions, by using algorithms and statistical models to analyze and draw inferences from patterns in data.\"the application of machine learning to biological databases has increased\"\n"
     ]
    }
   ],
   "source": [
    "print(ask_google('what is the definition of machine learning'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e64d175e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is the silliest you have ever felt?\n",
      "TRY - ask wiki now, so it might be shitty\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ask_google('What is the silliest you have ever felt?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3397fab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q when is us independence?\n",
      "Q: when is? \n",
      "Selasa, 4 Juli\n"
     ]
    }
   ],
   "source": [
    "question1=\"When is US independence?\"\n",
    "print(ask_google(question1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8bb00647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: who is the president of united states?\n",
      "Joe Biden - Amerika Serikat/Presiden\n"
     ]
    }
   ],
   "source": [
    "question2=\"Who is the president of United States?\"\n",
    "print(ask_google(question2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34d72443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: who is google ceo?\n",
      "Sundar Pichai - Google/CEO\n"
     ]
    }
   ],
   "source": [
    "question2b=\"who is google ceo?\"\n",
    "print(ask_google(question2b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49a3db1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is a book?\n",
      "A book is a medium for recording information in the form of writing or images, typically composed of many pages (made of papyrus, parchment, vellum, or paper) bound together and protected by a cover. The technical term for this physical arrangement is codex (plural, codices).\n",
      "A book is a medium for recording information in the form of writing or images, typically composed of many pages (made of papyrus, parchment, vellum, or paper) bound together and protected by a cover. The technical term for this physical arrangement is codex (plural, codices).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question3=\"what is a book?\"\n",
    "print(ask_google(question3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f42ff4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q how to cook chicken soup\n",
      "why-how\n",
      "how to____ source: wikihow? \n",
      "Make Chicken Soup\n",
      "1 - Soak the chicken in cold water only if necessary.\n",
      "2 - Check the internal cavity.\n",
      "3 - Trim excess fat.\n",
      "4 - Remove the legs.\n",
      "5 - Remove the wings.\n",
      "6 - Cut up the breast.\n",
      "7 - Place chicken pieces in a large stock pot.\n",
      "8 - Add water to cover, salt, and bay leaf.\n",
      "9 - Cover the pot and bring to boil.\n",
      "10 - Uncover and skim off the top froth.\n",
      "11 - Allow to simmer about 2 1/4 hours.\n",
      "12 - Add the onions, celery, and carrots and a pinch or two of parsley.\n",
      "13 - Allow to simmer about 45 minutes.\n",
      "14 - Strain soup, saving the broth.\n",
      "15 - Optionally, place cooked noodles or rice in bowl and add soup.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question4=\"how to cook chicken soup\"\n",
    "print(ask_google(question4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c599b872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q why is the sky blue\n",
      "why-how\n",
      "Q: why is ___ cond? \n",
      "Blue light is scattered in all directions by the tiny molecules of air in Earth's atmosphere. Blue is scattered more than other colors because it travels as shorter, smaller waves. This is why we see a blue sky most of the time. Closer to the horizon, the sky fades to a lighter blue or white.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question5=\"why is the sky blue\"\n",
    "print(ask_google(question5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ca813f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: google belongs to which country?\n",
      "Google LLC (/ˈɡuːɡəl/ ( listen)) is an American multinational technology company that focuses on search engine technology, online advertising, cloud computing, computer software, quantum computing, e-commerce, artificial intelligence, and consumer electronics.\n"
     ]
    }
   ],
   "source": [
    "question6=\"Google belongs to which country?\"\n",
    "print(ask_google(question6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "05c5a698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: where is the center of the earth\n",
      "Woods, a physicist with Gulf Energy and Environmental Systems in San Diego, California, used a digital global map and calculated the coordinates on a mainframe system as 39°00′N 34°00′E, in modern-day Turkey, near the district of Kırşehir, Kırşehir Province, approx. 1,800 km north of Giza.\n"
     ]
    }
   ],
   "source": [
    "question7=\"where is the center of the earth\"\n",
    "print(ask_google(question7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0565bfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: which town is the center of the earth\n",
      "In 2003, a refined result was yielded by Holger Isenberg: 40°52′N 34°34′E, also in Turkey, near the district of İskilip, Çorum Province, approx. 200 km northeast of Ankara. In 2016, Google Maps marked Isenberg's result of 40°52′N 34°34′ECoordinates: 40°52′N 34°34′E as the geographical center of Earth.\n"
     ]
    }
   ],
   "source": [
    "#where, what if\n",
    "\n",
    "question8=\"Which town is the center of the earth\"\n",
    "print(ask_google(question8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "454224d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: why am i here?\n",
      "I am sorry I don't know about the answer to the question - Why am i here?. I will keep learning\n"
     ]
    }
   ],
   "source": [
    "#where, what if\n",
    "\n",
    "question8=\"Why am i here?\"\n",
    "print(ask_google(question8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26e5fd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: if you found out you were going to die tomorrow, what would you do today\n",
      "I am sorry I don't know about the answer to the question - If you found out you were going to die tomorrow, what would you do today. I will keep learning\n"
     ]
    }
   ],
   "source": [
    "question9='If you found out you were going to die tomorrow, what would you do today'\n",
    "print(ask_google(question9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7904494c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what to do if google topic database does not connect to wikidata database \n",
      "\n",
      "I am sorry I don't know about the answer to the question - what to do if google topic database does not connect to wikidata database . I will keep learning\n"
     ]
    }
   ],
   "source": [
    "question9='what to do if google topic database does not connect to wikidata database '\n",
    "print(ask_google(question9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65228e2d",
   "metadata": {},
   "source": [
    "# Notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0b25e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers crawler\n",
    "def answers(urls_list, save_path):\n",
    "    browser = connect_chrome()\n",
    "    url_index = -1\n",
    "    loop_limit = len(urls_list)\n",
    "    # output file containing all answers\n",
    "    file_answers = open(Path(save_path) / \"answers.txt\", mode='a')\n",
    "    print('Starting the answers crawling...')\n",
    "    while True:\n",
    "        url_index += 1\n",
    "        print('--------------------------------------------------')\n",
    "        if url_index >= loop_limit:\n",
    "            print('Crawling completed, answers have been saved to  :  ', save_path)\n",
    "            browser.quit()\n",
    "            file_answers.close()\n",
    "            break\n",
    "        current_line = urls_list[url_index]\n",
    "        print('processing question number  : ' + str(url_index + 1))\n",
    "        print(current_line)\n",
    "        if '/unanswered/' in str(current_line):\n",
    "            print('answer is unanswered')\n",
    "            continue\n",
    "        question_id = current_line\n",
    "        # opening Question page\n",
    "        try:\n",
    "            browser.get(current_line)\n",
    "            time.sleep(2)\n",
    "        except Exception as OpenEx:\n",
    "            print('cant open the following question link : ', current_line)\n",
    "            print('Error on line {}'.format(sys.exc_info()[-1].tb_lineno), type(OpenEx).__name__, OpenEx)\n",
    "            print(str(OpenEx))\n",
    "            continue\n",
    "        try:\n",
    "            nb_answers_text = WebDriverWait(browser, 10).until(\n",
    "                EC.visibility_of_element_located((By.XPATH, \"//div[text()[contains(.,'Answer')]]\"))).text\n",
    "            nb_answers = [int(s.strip('+')) for s in nb_answers_text.split() if s.strip('+').isdigit()][0]\n",
    "            print('Question have :', nb_answers_text)\n",
    "        except Exception as Openans:\n",
    "            print('cant get answers')\n",
    "            print('Error on line {}'.format(sys.exc_info()[-1].tb_lineno), type(Openans).__name__, Openans)\n",
    "            print(str(Openans))\n",
    "            continue\n",
    "        # nb_answers_text = browser.find_element_by_xpath(\"//div[@class='QuestionPageAnswerHeader']//div[@class='answer_count']\").text\n",
    "\n",
    "        if nb_answers > 7:\n",
    "            scroll_down(browser, 'answers')\n",
    "        continue_reading_buttons = browser.find_elements_by_xpath(\"//a[@role='button']\")\n",
    "        time.sleep(2)\n",
    "        for button in continue_reading_buttons:\n",
    "            try:\n",
    "                ActionChains(browser).click(button).perform()\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                print('cant click more')\n",
    "                continue\n",
    "        time.sleep(2)\n",
    "        html_source = browser.page_source\n",
    "        soup = BeautifulSoup(html_source, \"html.parser\")\n",
    "        # get the question-id\n",
    "        question_id = current_line.rsplit('/', 1)[-1]\n",
    "        # find title\n",
    "        title = current_line.replace(\"https://www.quora.com/\", \"\")\n",
    "        # find question's topics\n",
    "        questions_topics = soup.findAll(\"div\", {\"class\": \"q-box qu-mr--tiny qu-mb--tiny\"})\n",
    "        questions_topics_text = []\n",
    "        for topic in questions_topics:\n",
    "            questions_topics_text.append(topic.text.rstrip())\n",
    "        # number of answers\n",
    "        # not all answers are saved!\n",
    "        # answers that collapsed, and those written by anonymous users are not saved\n",
    "        try:\n",
    "            split_html = html_source.split('class=\"q-box qu-pt--medium qu-pb--medium\"')\n",
    "        except Exception as not_exist:  # mostly because question is deleted by quora\n",
    "            print('question no long exists')\n",
    "            print('Error on line {}'.format(sys.exc_info()[-1].tb_lineno), type(not_exist).__name__, not_exist)\n",
    "            print(str(not_exist))\n",
    "            continue\n",
    "        # The underneath loop will generate len(split_html)/2 exceptions, cause answers in split_html\n",
    "        # are either in Odd or Pair positions, so ignore printed exceptions.\n",
    "        # print('len split : ',len(split_html))\n",
    "        for i in range(1, len(split_html)):\n",
    "            try:\n",
    "                part = split_html[i]\n",
    "                part_soup = BeautifulSoup(part, \"html.parser\")\n",
    "                # print('===============================================================')\n",
    "                # find users names of answers authors\n",
    "                try:\n",
    "                    authors = part_soup.find(\"a\", href=lambda href: href and \"/profile/\" in href)\n",
    "                    user_id = authors['href'].rsplit('/', 1)[-1]\n",
    "                # print(user_id)\n",
    "                except Exception as not_exist2:  # mostly because question is deleted by quora\n",
    "                    print('author extract pb')\n",
    "                    print('Error on line {}'.format(sys.exc_info()[-1].tb_lineno), type(not_exist2).__name__,\n",
    "                          not_exist2)\n",
    "                    print(str(not_exist2))\n",
    "                    continue\n",
    "\n",
    "                # find answer dates\n",
    "\n",
    "                answer_date = part_soup.find(\"a\", string=lambda string: string and (\n",
    "                        \"Answered\" in string or \"Updated\" in string))  # (\"a\", {\"class\": \"answer_permalink\"})\n",
    "                try:\n",
    "                    date = answer_date.text\n",
    "                    if \"Updated\" in date:\n",
    "                        date = date[8:]\n",
    "                    else:\n",
    "                        date = date[9:]\n",
    "                    date = dateparser.parse(date).strftime(\"%Y-%m-%d\")\n",
    "                except:  # when updated or answered in the same week (ex: Updated Sat)\n",
    "                    date = dateparser.parse(\"7 days ago\").strftime(\"%Y-%m-%d\")\n",
    "                # print(date)\n",
    "                # find answers text\n",
    "                answer_text = part_soup.find(\"div\", {\"class\": \"q-relative spacing_log_answer_content\"})\n",
    "                # print(\" answer_text\", answer_text.text)\n",
    "                answer_text = answer_text.text\n",
    "                # write answer elements to file\n",
    "                s = str(question_id.rstrip()) + '\\t' + str(date) + \"\\t\" + user_id + \"\\t\" + str(\n",
    "                    questions_topics_text) + \"\\t\" + str(answer_text.rstrip()) + \"\\n\"\n",
    "                # print(\"writing down the answer...\")\n",
    "                file_answers.write(s)\n",
    "                print('writing down answers...')\n",
    "            except Exception as e1:  # Most times because user is anonymous ,  continue without saving anything\n",
    "                print('---------------There is an Exception-----------')\n",
    "                print('Error on line {}'.format(sys.exc_info()[-1].tb_lineno), type(e1).__name__, e1)\n",
    "                print(str(e1))\n",
    "                o = 1\n",
    "\n",
    "        # we sleep every while in order to avoid IP ban\n",
    "        if url_index % 3 == 2:\n",
    "            sleep_time = (round(random.uniform(5, 10), 1))\n",
    "            time.sleep(sleep_time)\n",
    "    browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac836de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywikihow import RandomHowTo\n",
    "\n",
    "how_to = RandomHowTo()\n",
    "how_to.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae5d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywikihow import WikiHow, search_wikihow\n",
    "\n",
    "\n",
    "max_results = 1  # default for optional argument is 10\n",
    "how_tos = search_wikihow(\"how to learn programming\", max_results)\n",
    "assert len(how_tos) == 1\n",
    "how_tos[0].print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a65503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for efficiency and to get unlimited entries, the best is to use the generator\n",
    "for how_to in WikiHow.search(\"how to learn python\"):\n",
    "    how_to.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywikihow import HowTo\n",
    "\n",
    "how_to = HowTo(\"https://www.wikihow.com/Train-a-Dog\")\n",
    "\n",
    "data = how_to.as_dict()\n",
    "\n",
    "#print(how_to.url)\n",
    "#print(how_to.title)\n",
    "#print(how_to.intro)\n",
    "#print(how_to.n_steps)\n",
    "print(how_to.summary)\n",
    "\n",
    "first_step = how_to.steps[0]\n",
    "#first_step.print()\n",
    "data = first_step.as_dict()\n",
    "\n",
    "#how_to.print(extended=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e2d403",
   "metadata": {},
   "source": [
    "\n",
    "# Option 2:\n",
    "'''\n",
    "ap·ple\n",
    "ˈapəl\n",
    "the round fruit of a tree of the rose family, which typically has thin red or green skin and crisp flesh. Many varieties have been developed as dessert or cooking fruit or for making cider.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93f5fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, lxml\n",
    "\n",
    "def q_google(question):\n",
    "    headers = {\n",
    "        'User-agent':\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.19582\"\n",
    "    }\n",
    "\n",
    "    html = requests.get(f'https://www.google.de/search?q={question}', headers=headers)\n",
    "    soup = BeautifulSoup(html.text, 'lxml')\n",
    "\n",
    "    syllables = soup.select_one('.frCXef span').text\n",
    "    phonetic = soup.select_one('.g30o5d span span').text\n",
    "    noun = soup.select_one('.h3TRxf span').text\n",
    "    print(f'{syllables}\\n{phonetic}\\n{noun}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "007b33ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import random\n",
    "import userpaths\n",
    "import dateparser\n",
    "import argparse\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# -------------------------------------------------------------\n",
    "def connect_chrome():\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('log-level=3')\n",
    "    options.add_argument(\"--incognito\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    # try:\n",
    "    # \timport quora_scraper\n",
    "    # \tpackage_path=str(quora_scraper.__path__).split(\"'\")[1]\n",
    "    # \tdriver_path= Path(package_path) / \"chromedriver\"\n",
    "    # except:\n",
    "    # \tdriver_path= Path.cwd() / \"chromedriver\"\n",
    "    # driver_path= Path.cwd() / \"chromedriver\"\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(2)\n",
    "    return driver\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# -------------------------------------------------------------\n",
    "# remove 'k'(kilo) and 'm'(million) from Quora numbers\n",
    "def convert_number(number):\n",
    "    if 'k' in number:\n",
    "        n = float(number.lower().replace('k', '').replace(' ', '')) * 1000\n",
    "    elif 'm' in number:\n",
    "        n = float(number.lower().replace('m', '').replace(' ', '')) * 1000000\n",
    "    else:\n",
    "        n = number\n",
    "    return int(n)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# -------------------------------------------------------------\n",
    "# convert Quora dates (such as 2 months ago) to DD-MM-YYYY format\n",
    "def convert_date_format(date_text):\n",
    "    try:\n",
    "        if \"Updated\" in date_text:\n",
    "            date = date_text[8:]\n",
    "        else:\n",
    "            date = date_text[9:]\n",
    "        date = dateparser.parse(date_text).strftime(\"%Y-%m-%d\")\n",
    "    except:  # when updated or answered in the same week (ex: Updated Sat)\n",
    "        date = dateparser.parse(\"7 days ago\").strftime(\"%Y-%m-%d\")\n",
    "    return date\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# -------------------------------------------------------------\n",
    "def scroll_up(self, nb_times):\n",
    "    for iii in range(0, nb_times):\n",
    "        self.execute_script(\"window.scrollBy(0,-200)\")\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# -------------------------------------------------------------\n",
    "# method for loading  quora dynamic content\n",
    "def scroll_down(self, type_of_page='users'):\n",
    "    last_height = self.page_source\n",
    "    loop_scroll = True\n",
    "    attempt = 0\n",
    "    # we generate a random waiting time between 2 and 4\n",
    "    waiting_scroll_time = round(random.uniform(2, 4), 1)\n",
    "    print('scrolling down to get all answers...')\n",
    "    max_waiting_time = round(random.uniform(5, 7), 1)\n",
    "    # we increase waiting time when we look for questions urls\n",
    "    if type_of_page == 'questions': max_waiting_time = round(random.uniform(20, 30), 1)\n",
    "    # scroll down loop until page not changing\n",
    "    while loop_scroll:\n",
    "        self.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "        if type_of_page == 'answers':\n",
    "            scroll_up(self, 2)\n",
    "        new_height = self.page_source\n",
    "        if new_height == last_height:\n",
    "            # in case of not change, we increase the waiting time\n",
    "            waiting_scroll_time = max_waiting_time\n",
    "            attempt += 1\n",
    "            if attempt == 3:  # in the third attempt we end the scrolling\n",
    "                loop_scroll = False\n",
    "        # print('attempt',attempt)\n",
    "        else:\n",
    "            attempt = 0\n",
    "            waiting_scroll_time = round(random.uniform(2, 4), 1)\n",
    "        last_height = new_height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e25ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_list = ['What is the silliest you have ever felt?']\n",
    "save_path='answer.txt'\n",
    "answers(keywords_list, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45878bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3.5\n",
    "# defineterm.py\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import html\n",
    "import codecs\n",
    "\n",
    "searchterm = 'book'\n",
    "url = 'https://www.google.com/search?q=define+' + searchterm\n",
    "res = requests.get(url)\n",
    "try:\n",
    "    res.raise_for_status()\n",
    "except Exception as exc:\n",
    "    print('error while loading page occured: ' + str(exc))\n",
    "\n",
    "text = html.unescape(res.text)\n",
    "soup = BeautifulSoup(text, 'lxml')\n",
    "prettytext = soup.prettify()\n",
    "\n",
    "#next lines are for analysis (saving raw page), you can comment them\n",
    "frawpage = codecs.open('rawpage.txt', 'w', 'utf-8')\n",
    "frawpage.write(prettytext)\n",
    "frawpage.close()\n",
    "\n",
    "firsttag = soup.find('h3', class_=\"r\")\n",
    "if firsttag != None:\n",
    "    print(firsttag.getText())\n",
    "    print()\n",
    "\n",
    "#second tag may be changed, so check it if not returns correct result. That might be situation for all searched tags.\n",
    "secondtag = soup.find('div', {'style': 'color:#666;padding:5px 0'})\n",
    "if secondtag != None:\n",
    "    print(secondtag.getText())\n",
    "    print()\n",
    "\n",
    "termtags = soup.findAll(\"li\", {\"style\" : \"list-style-type:decimal\"})\n",
    "\n",
    "count = 0\n",
    "for tag in termtags:\n",
    "    count += 1\n",
    "    print( str(count)+'. ' + tag.getText())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b939429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'User-agent':\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.67 Safari/537.36'\n",
    "}\n",
    "\n",
    "def ask_google2(question):\n",
    "\n",
    "    html = requests.get(f'https://www.google.com/search?q=\"{question}', headers=headers)\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "    answer1=''\n",
    "    answer2=''\n",
    "    try:\n",
    "        \n",
    "        answer1 = soup.select_one('.IZ6rdc').text\n",
    "        answer2 = soup.select_one('.NFQFxe').text.strip(answer1)\n",
    "        print('Q: ___ belongs to which ____?, exp:Google belongs to which country?')\n",
    "        if answer2 !=\"\":\n",
    "            return f\"{answer1} - {answer2}\"\n",
    "        return answer1\n",
    "    except:\n",
    "        try:\n",
    "            \n",
    "        #answer = soup.select_one('.MUxGbd .wuQ4Ob .WZ8Tjf').text\n",
    "        #answer = soup.select_one('.WZ8Tjf').text\n",
    "            answer1 = soup.select_one('.FLP8od').text #\"LEsW6e DVGBBd\"><div class=\"wDYxhc NFQFxe oHglmf xzPb7d\" \n",
    "            answer2 = soup.select_one('.NFQFxe').text\n",
    "            print('Who is ___, exp: Who is the president of United States?')\n",
    "            if answer2 !=\"\":\n",
    "                return f\"{answer1} - {answer2}\"\n",
    "            return answer1\n",
    "        except:\n",
    "            try:\n",
    "                \n",
    "                answer1 = soup.select_one('.RqBzHd').text \n",
    "                print('cond3')\n",
    "                return answer1\n",
    "            except:\n",
    "                try:\n",
    "                    \n",
    "                    answer1=soup.select_one('.d9FyLd').text \n",
    "                    print('cond4')\n",
    "                    return answer1\n",
    "                except:\n",
    "                    try:\n",
    "                        \n",
    "                        #is __ better than ___?\n",
    "                        answer1=soup.select_one('.iKJnec').text \n",
    "                        print('cond is __ better than ___? ')\n",
    "                        return answer1\n",
    "                    except:\n",
    "                        try:\n",
    "                            #why the sky\n",
    "                            \n",
    "                            answer1=soup.select_one('.ILfuVd').text \n",
    "                            print('Q: why is ___ cond? ')\n",
    "                            return answer1\n",
    "                        except:\n",
    "                            try:\n",
    "                            #why the sky\n",
    "                            \n",
    "                                answer1=soup.select_one('.zCubwf').text \n",
    "                                print('Q: when is? ')\n",
    "                                return answer1\n",
    "                            \n",
    "                            except:\n",
    "                                try:\n",
    "                                    answer1=soup.select_one('.hgKElc').text \n",
    "                                    print('Q: where is? ')\n",
    "                                    return answer1\n",
    "                                    \n",
    "                                except:\n",
    "                                    try:\n",
    "\n",
    "                                        #how to?\n",
    "                                        answer1=how_to(question)\n",
    "                                        print('how to____ source: wikihow? ')\n",
    "                                        return answer1\n",
    "\n",
    "                                    except:\n",
    "                                        print('cond6')\n",
    "                                        answer2=soup.text\n",
    "                                        answer1=\"Cannot find answer\"\n",
    "                                        if answer1==\"Cannot find answer\":\n",
    "                                            print(\"ask wiki now, so it might be shitty\")\n",
    "                                            #if \"what is\" in question.lower():\n",
    "                                            answer1 = wiki_summary(question.strip('?').upper().strip('WHAT IS'))\n",
    "                                            return answer1\n",
    "\n",
    "    answer2=answer2.split('.')[0]\n",
    "    #print(soup)\n",
    "    return answer1,answer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b63b447",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chatterbot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_3/h3zgh6c16nn92sj9z08yw2rc0000gp/T/ipykernel_1727/402714102.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import \"chatbot\" from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# chatterbot package.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mchatterbot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatBot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Inorder to train our bot, we have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chatterbot'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import \"chatbot\" from\n",
    "# chatterbot package.\n",
    "from chatterbot import ChatBot\n",
    "  \n",
    "# Inorder to train our bot, we have\n",
    "# to import a trainer package\n",
    "# \"ChatterBotCorpusTrainer\"\n",
    "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
    " \n",
    "  \n",
    "# Give a name to the chatbot “corona bot”\n",
    "# and assign a trainer component.\n",
    "chatbot=ChatBot('corona bot')\n",
    " \n",
    "# Create a new trainer for the chatbot\n",
    "trainer = ChatterBotCorpusTrainer(chatbot)\n",
    "  \n",
    "# Now let us train our bot with multiple corpus\n",
    "trainer.train(\"chatterbot.corpus.english.greetings\",\n",
    "              \"chatterbot.corpus.english.conversations\" )\n",
    "  \n",
    "response = chatbot.get_response('What is your Number')\n",
    "print(response)\n",
    " \n",
    "response = chatbot.get_response('Who are you?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ffc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24975865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
